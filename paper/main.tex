\documentclass[11pt]{article}

\bibliographystyle{ieeetr}

\usepackage{graphicx} % Required for inserting images
\usepackage{hyperref}
\usepackage{acronym}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{multirow}
\usepackage{rotating}
\usepackage{pifont}
\usepackage{tikz}
\usepackage{enumitem}
\usetikzlibrary{positioning,arrows.meta, shapes.geometric}

\usepackage{amsmath}
\usepackage{caption}
\usepackage[margin=1in]{geometry}
\usepackage{cleveref}
\usepackage{float}
% --- Helper commands for the symbols ---
\newcommand{\cmark}{\ding{51}}% checkmark
\newcommand{\xmark}{\ding{55}}% cross

% Acronym table
\acrodef{CC}{Cloud Computing}
\acrodef{EC}{Edge Computing}
\acrodef{FC}{Fog Computing}
\acrodef{CECC}{Cloud Edge Computing Continuum}
\acrodef{AI}{Artificial Intelligence}
\acrodef{VM}{Virtual Machine}
\acrodef{IoT}{Internet of Things}
\acrodef{QoS}{Quality-of-Service}
\acrodef{ES}{Edge Server}
\acrodef{FS}{Fog Server}
\acrodef{CS}{Cloud Server}

\acrodef{CSP}{Cloud Service Provider}
\acrodef{SaaS}{Software as a Service}
\acrodef{PaaS}{Platform as a Service}
\acrodef{IaaS}{Infrastructure as a Service}
\acrodef{FaaS}{Function as a Service}

\title{Energy-Aware Service Placement in Edge}
\author{Théo HARDY}
\date{2025}

\begin{document}

\maketitle

\section{Introduction}

% Talk about IoT

\section{Introduction on Edge/Fog Computing}

\subsection{Cloud Computing}

\ac{CC} has established itself as the ubiquitous backbone of modern computing environments. One of its primary advantages is economic efficiency; it enables small- and medium-sized enterprises (SMEs) to access powerful server resources at a relatively low cost, eliminating the need for significant upfront capital expenditure on proprietary hardware \cite{jiang2019cloud}. Leveraging vast networks of remote servers, \ac{CC} can dynamically provision computing, storage, and networking services in real-time, tailoring resources to precise user requirements regarding type and quantity \cite{othman2013survey}.

This market is currently led by major industry players, including Google (Google Cloud), Amazon (AWS), and Microsoft (Azure) \cite{hua2023edge}. Beyond standalone services, research has increasingly focused on the synergistic relationship between Cloud and \ac{IoT}, a paradigm often referred to as CloudIoT \cite{botta2016integration}. This integration aims to revolutionize diverse sectors, from smart cities and ubiquitous healthcare to business process optimization. As a centralized solution, \ac{CC} remains a critical enabler of the \ac{IoT}, providing the elasticity and virtually unlimited resources required to execute computation-intensive \ac{IoT} applications \cite{deng2020optimal}.

\subsection{Edge/Fog Computing}

\ac{EC} essentially migrates partial computing tasks from \ac{CC} to local edge servers. It is an emergent informatic paradigm aiming to complete (not replace) the cloud architecture. Edge computing is essentially an edge optimization of \ac{CC}. Both of them are designed for handling big data. However, the main difference is that data can be distributed and processed on the closer edge servers in \ac{EC}. It performs data preprocessing and analysis near the data sources\cite{kong2022edge}. It should be noted that \ac{EC} cannot replace the roles and advantages of \ac{CC} because the cloud retains indispensable computing power and storage capacity. \ac{EC} and \ac{CC} should cooperate efficiently and securely \cite{hua2023edge}. \Cref{tab:comparison_edge_cloud} shows a comparison between Edge and Cloud Computing. 

\begin{table}[ht!]
    \centering
    \caption{Comparison of Edge Computing and Cloud Computing}
    \label{tab:comparison_edge_cloud}
    
    % The 'X' columns will wrap text
    \begin{tabularx}{\textwidth}{ |l|X|X| } 
        \hline
        \textbf{} & \textbf{Edge Computing} & \textbf{Cloud Computing} \\
        \hline 
        \textbf{Computation Location}    & Local device  / At the periphery of the network & Centralized big data centers / Upper-most layer in the architecture \\

        \hline
        \textbf{Network Components}    & Terminal device, edge device and \ac{IoT} gateways, Core network hardwares & All basic network components, Data centers\\
        \hline
        \textbf{Resource Capability} &  Uses limited resources / often resource-constrained &Offers powerful computing resources and storage capacity \\
        \hline

        \textbf{Bandwidth Requirements} &  Low dependency on network connectivity / Reduces pressure on network bandwidth &High network bandwidth requirement / Data transfer to remote servers is bandwidth-limited \\
                \hline
        
        \textbf{Scalability \& Deployment} & High flexibility and scalability / Temporary deployment or deployment with minimal planning  & Low flexibility and scalability / Complex deployment\\
        \hline
    \end{tabularx}
\end{table}

Some works also explore the more recent \ac{FC} paradigm \cite{salaht2020overview, lone2023review} introduced in 2012 by Cisco \cite{bonomi2012fog}. Although both \ac{EC} and \ac{FC} aim to reduce latency and bandwidth consumption by moving processing closer to the user, they operate at different layers:
\begin{itemize}
    \item Edge computing (\ac{EC}) processes data directly on end-devices or nearby gateways, enabling immediate responses.
    \item Fog Computing (\ac{FC}) operates somewhat closer to the network core, often in a position between the edge devices and the centralized cloud on smart routers, gateways or network switches. The \ac{FC} layer handles more complex data processing, aggregation, filtering, and analytics capabilities before data is potentially forwarded up to the cloud.
\end{itemize}

Many studies consider the \ac{FC} part of the \ac{EC} paradigm, or integrate the two under the broader "Fog/Edge paradigm" \cite{alsadie2024comprehensive}. \Cref{fig:cocentric_cloud_scheme} shows the difference in geographic distribution between \ac{EC}, \ac{FC}, \ac{CC}.

\begin{figure}[ht!]
    \centering 
    
    \includegraphics[width=0.70\textwidth]{figures/Cloud_Fog_Edge_scheme.pdf}
    
    % [width=0.9\textwidth] makes it 90% of the text width
    
    \caption{Cloud Fog and Edge} 
    \label{fig:cocentric_cloud_scheme}    
\end{figure}
% --- END FIGURE ---

\subsection{Motivations of Edge/Fog Computing}

However, the high computing power of centralized \ac{CC} has begun to show limitations in the face of modern data demands. The \ac{IoT} represents one of the most rapidly advancing domains in computing history, and its expansion has ushered in an era of unprecedented data generation. Projections indicate that the number of interconnected devices will soar to approximately 125 billion by 2030 \cite{saadouni2025identification}. This explosion in connected devices inevitably leads to the generation of massive amounts of data that require timely processing.

The core limitations of the traditional cloud-centric architecture stem from the inherent geographical distance between distributed data sources (\ac{IoT} devices) and remote cloud servers. This centralized model results in significant data congestion, high latency, and unacceptable delays for time-sensitive applications. For many critical \ac{IoT} scenarios, such as the Internet of Vehicles (IoV), the application requirements necessitate ultra-high speed and ultra-low latency \cite{qin2018power, zhang2019mobile}.

\ac{EC} emerges as a paradigm designed to address these fundamental CC limitations, offering numerous benefits by distributing resources closer to the data source.

\begin{itemize}
    \item \textbf{Ultra-Low Latency}: \ac{EC}  provides ultra-low latency by enabling data processing closer to where the data is generated \cite{apat2023comprehensive}.
    \item \textbf{Energy Efficiency}: By sending data to local edge servers instead of distant, remote cloud data centers, the energy consumption of individual \ac{IoT} nodes can be significantly decreased.
    \item \textbf{Scalability}: Edge nodes and \ac{FC} infrastructure offer moderate computing resources in a distributed manner. This enables \ac{EC}  to provide excellent scalability that satisfies the demands of large-scale \ac{IoT} applications, such as smart cities and autonomous driving \cite{kong2022edge}. This scalability is significantly eased by the integration of \ac{FaaS} with \ac{IoT} and \ac{EC} that improve modularity, resource utilization, and elastic scaling \cite{ghaseminya2025advancing}.
\end{itemize}

While individual \ac{IoT} devices cannot match the computational power of centralized data centers, there is a clear and significant trend of them becoming more performant. This increase in on-device processing capability is a crucial enabler for \ac{EC}, allowing for data pre-filtering and local analytics that reduce latency and bandwidth consumption.

\subsection{Limitations of Edge/Fog Computing}

% scalibity 

However, \ac{EC} also face some limitations that are hard to tackle today : 
\begin{itemize}
    \item \textbf{Resource allocation} : \ac{EC}'s primary advantage over traditional \ac{CC} is its ability to perform computation and storage tasks locally, eliminating the need to upload all data to the cloud. However, because tasks are distributed across resource-constrained edge nodes, an intelligent and efficient resource management solution is crucial for \ac{EC}'s success \cite{hua2023edge}.
    \item \textbf{Data security and privacy} : The heterogeneous nature of \ac{EC} makes traditional security and privacy solutions designed for centralized cloud models inadequate for non-centralized architecture, making the enhancement of data security and privacy protection a critical area for research\cite{apat2023comprehensive}.
\end{itemize}

\subsection{Cloud Edge Computing Continuum Paradigm}

The \acf{CECC} (also known as the Digital Continuum or Transcontinuum) represents an advanced paradigm in the \ac{CC} domain. Instead of viewing the architecture as rigidly separated layers, it conceives of Edge, Fog, and Cloud as a single, cohesive, and continuous computational infrastructure. This unification enables a seamless and dynamic flow of data and tasks, allowing them to be strategically placed at the most appropriate point in the infrastructure based on their specific requirements (e.g., latency, privacy, or processing power).

This integrated model facilitates a logical and efficient processing pipeline. Typically, data is first generated and preprocessed directly on Edge devices to handle time-sensitive actions. From there, intermediate Fog nodes can perform further processing and partial aggregation. Finally, computationally intensive workloads such as Big Data analytics, large-scale AI model training, or complex global simulations are transferred to the HPC-enabled Cloud data centers that possess the necessary resources \cite{rosendo2022distributed}.

These infrastructural federations, are seen as the critical computing fabric for modern digital society as the Europe Commission views the Continuum as a key strategic technology to drive the region's digital transformation \cite{montevecchi2020energy}.

\section{Energy aware Cloud Edge Computing Continuum}

According to Anders Andrae, who works on sustainable ICT at Huawei Technologies Sweden, in 2030, data centers as a whole will consume as much as 8\% of global electrical supply \cite{jones2018stop}. \ac{CC} cleary has a significant environmental impact as 80\% of world's energy is still generated by brown energy sources (non-renewable) such as fossil fuels.


\section{Literature review: Devices Energy Formulation}
% De voir les papiers comment ils l'ont modélisé
% Est-ce que c'est une estimation, quel ordre de grandeur (est-ce les mêmes ??)
% est-ce c'est via une formule, est-ce qu'on retrouve pratiquement la meme chose ? 
% multi or mono objective 

\Cref{tab:related_work} summarizes the distinctions between recent contributions in the domain of energy-aware Edge Computing. A primary differentiator among these works is the scope of the continuum coverage and the optimization technique employed.

\Cref{tab:energy_metrics} summarizes the specific energy modeling approaches found in the literature, categorizing them by the types of devices covered (IoT, Edge/Fog, Cloud), the nature of the energy components (Dynamic vs. Static), and the methodology used to derive the values (Measured, Physical Estimation, or Simulation Parameters).

% --- BEGIN ROTATED LANDSCAPE TABLE ---
\begin{sidewaystable}[htbp] % This puts the table on its own landscape page
    \centering
    \footnotesize
    \caption{A comparison of related work on Energy Aware Cloud Edge Computing Continuum}
    \label{tab:related_work}
    
    % We define the column types. 'l' for left, 'c' for center,
    % and 'p{width}' for a paragraph column that wraps text.
\begin{tabularx}{\textheight}{ X X ccc cccc X X X X }
    \toprule % Top line
    
    % --- This is the complex 2-row header ---
    \multirow{1}{*}{Source} & 
    \multirow{2}{*}{Type of Model} & 
    \multicolumn{3}{c}{Continuum Coverage} & 
    \multicolumn{4}{c}{Optimization Objectives} & 
    \multirow{2}{*}{Technique} & 
    \multirow{2}{*}{Energy Model} & 
    \multirow{2}{*}{Application} & 
    \multirow{2}{*}{Evaluation} \\
    
    % Partial lines under the multi-column headers
    \cmidrule(lr){3-5} \cmidrule(lr){6-9}
    
    % This is the second row of the header
    &  & Edge & Fog & Cloud & Energy & Cost & Latency & Other & & & & \\
    
    \midrule % Line between header and data
    
    % Rows sorted by Year (Descending)

    2025 \cite{laso2025energy} &
    Workload prediction &
    \cmark & \xmark & \xmark &
    \cmark & \xmark & \xmark & \cmark &
    BiLSTM, CNN \& Math Models &
    CPU utilization-based (cores) &
    Microservices &
    Real nodes \& Azure data \\
    \midrule
    
    2024 \cite{paipuri2024ceems} &
    Monitoring stack &
    \xmark & \xmark & \cmark &
    \cmark & \xmark & \xmark & \cmark &
    Software counters (RAPL/IPMI) &
    CPU, DRAM, GPU \& Network &
    HPC jobs \& Bare-metal &
    Supercomputer (Jean-Zay) \\
    \midrule
    
    2024 \cite{baneshi2024analyzing} &
    Simulation approach &
    \cmark & \xmark & \cmark &
    \cmark & \xmark & \cmark & \cmark &
    Enhanced iFogSim framework &
    Computation \& NIC (Networking) &
    Video Surveillance &
    Simulation (iFogSim) \\
    \midrule

    2023 \cite{jeong2023towards} &
    Service scheduling &
    \cmark & \xmark & \cmark &
    \cmark & \xmark & \cmark & \cmark &
    Reinforcement Learning \& Heuristics &
    Server, Link, \& Migration &
    Delay-sensitive services &
    Simulation (CloudSim SDN) \\
    \midrule

    2023 \cite{iftikhar2023hunterplus} &
    Task Scheduling &
    \xmark & \cmark & \cmark &
    \cmark & \xmark & \cmark & \cmark &
    CNN \& Bidirectional GRU &
    Hardware \& Cooling (PUE) &
    Heterogeneous AI tasks &
    Real environment (Azure VMs) \\
    \midrule
    
    2022 \cite{naha2022multiple} &
    Resource allocation &
    \cmark & \cmark & \xmark &
    \cmark & \cmark & \cmark & \cmark &
    Multiple Linear Regression &
    Predictive Model (from CPU) &
    Time-sensitive IoT &
    Simulation (CloudSim) \\
    \midrule

    2022 \cite{cui2022energy} &
    Edge Server Mgmt &
    \cmark & \xmark & \xmark &
    \cmark & \xmark & \cmark & \cmark &
    Potential Game Theory &
    Switch \& PM Running costs &
    Mobile Edge users &
    Simulation \& Testbed \\
    \midrule

    2021 \cite{goudarzi2021distributed} &
    DAG Application placement &
    \cmark & \cmark & \cmark &
    \cmark & \xmark & \cmark & \xmark &
    Distributed DRL (IMPALA) &
    IoT Device Only &
      IoT &
    Simulation \& Testbed \\
    \midrule

    2021 \cite{ahvar2021deca} &
    Application placement &
    \cmark & \xmark & \xmark &
    \cmark & \cmark & \xmark & \cmark &
    A* algorithm \& Fuzzy Sets &
    CNs \& Network devices &
    Microservice components &
    Simulation (CloudSim) \\
    \midrule
    
    2021 \cite{jeong2023towards} &
    Service scheduling &
    \cmark & \xmark & \cmark &
    \cmark & \xmark & \cmark & \cmark &
    Q-Learning \& Heuristics &
    Server, Link, \& Migration &
    Real-time services &
    Simulation (CloudSimSDN) \\
    \midrule
    
    2019 \cite{adhikari2019energy} &
    offloading strategy &
    \cmark & \cmark & \cmark &
    \cmark & \xmark & \cmark & \cmark &
    Firefly Alg. \& WSM &
    Computation \& Tx Models &
    Intensive IoT &
    Simulation (2 datasets) \& Stat. analysis \\
    \midrule
    
    2019 \cite{ahvar2019estimating} &
    Estimation model &
    \cmark & \cmark & \cmark &
    \cmark & \xmark & \xmark & \cmark &
    Piecewise linear taxonomy &
    PMs, Switches, \& Cooling &
    Continuum architectures &
    Simulation analysis \\
    
    \bottomrule % Bottom line
\end{tabularx}
 \end{sidewaystable}
 % --- END ROTATED LANDSCAPE TABLE ---


Energy efficiency remains a critical constraint in the design of Cloud, Fog, and Edge computing architectures. The literature proposes various mathematical models to quantify energy consumption, ranging from high-level utilization-based heuristics to low-level physics-based formulations. This section categorizes these approaches into computational energy (servers and nodes), IoT-specific constraints, communication overheads, and security-aware modeling.

\subsection{Server and Cloud Energy Models}
The modeling of server energy consumption is a multifaceted domain, encompassing diverse methodologies ranging from simplified linear approximations and utilization-based heuristics to highly granular physics-based formulations and real-time observational frameworks.

\subsubsection{Utilization-Based Linear Models}
A common approach in resource scheduling is to model server energy as a linear function of CPU utilization. Laso et al. adopted the mathematical framework established by Enokido et al. \cite{enokido2014extended} for their Microservice Energy Consumption and Workload Forecaster \cite{laso2025energy}. Their model calculates node power consumption based on the idle power ($E_{min}$), maximum power at full utilization ($E_{max}$), current CPU utilization ($U_{CPU}$), and the number of cores ($n_{cores}$):
$$
E=E_{min}+\frac{E_{max}-E_{min}}{n_{cores}}\times \lceil U_{CPU}\times n_{cores} \rceil
$$
This formulation allows the transformation of predicted CPU utilization into precise energy consumption estimates, which Laso et al. empirically validated for microservices.

Similarly, Jeong et al. proposed a model for Federated Edge Clouds where server energy is composed of a static base load and a dynamic component proportional to CPU load \cite{jeong2023towards}, aligning closely with Enokido et al.'s formulation. This linear approach is widely favored for its applicability to virtual machine (VM) scheduling due to its computational simplicity. Naha et al. further extended this concept by utilizing PlanetLab workload traces to derive energy consumption through regression analysis of CPU utilization in Fog devices, prioritizing empirical validation over purely theoretical modeling \cite{naha2022multiple}.

\subsubsection{Holistic and Non-Linear Models}
While linear models offer simplicity, recent works like the HunterPlus framework by Iftikhar et al. argue for a holistic approach that accounts for non-linear behaviors and infrastructure overheads \cite{iftikhar2023hunterplus}. They define total energy $E_{T}$ as the sum of computing hardware and cooling infrastructure:
$$
    E_{T} = E_{Comp} + E_{Cool}
$$
where $E_{Cool}$ explicitly accounts for the energy of air conditioners, fans, and pumps often overlooked in pure computational models. Furthermore, they refine the dynamic processor energy model by introducing a non-linear quadratic dependence on CPU utilization ($u$), offering a more realistic representation of load dynamics than simple linear models:
$$
     E_{dy}^{non-lin} = \mu_{1} \cdot u + \mu_{2} \cdot u^2
$$
where $\mu_1$ and $\mu_2$ are model-specific coefficients.

\subsubsection{Real-Time Observational Frameworks}
In contrast to predictive models that estimate energy via resource proxies (such as CPU utilization), recent frameworks prioritize direct empirical observation. Paipuri et al. propose CEEMS (Compute Energy \& Emissions Monitoring Stack), a resource-manager agnostic framework that shifts from modeling to real-time measurement \cite{paipuri2024ceems}.  

Instead of theoretical regression, CEEMS aggregates telemetry directly from hardware sensors—specifically RAPL (Running Average Power Limit) for CPUs and IPMI (Intelligent Platform Management Interface) for system-level power. This allows for the calculation of operational carbon emissions $CE_{op}$ by coupling precise energy measurements with real-time carbon intensity data $CI_{grid}$ fetch from external APIs like Electricity Map\footnote{\url{https://app.electricitymaps.com/}}:
$$
    CE_{op}(t) = E_{measured}(t) \times CI_{grid}(t)
$$
This approach addresses the gap between estimated models and actual hardware behavior in heterogeneous environments.


\subsubsection{Analytical and Physics-Based Models}

While statistical and regression-based models are effective for high-level estimation, they often lack the granularity required to understand the underlying causes of power dissipation. Analytical and physics-based approaches aim to bridge this gap by deriving energy consumption from fundamental circuit properties or rigorous state-machine definitions. These models are particularly valuable when designing energy-efficient hardware or when precise theoretical bounds are required.

\paragraph{a. State-Based Integral Models}
Moving beyond linear approximations, Saraswat et al. differentiate energy calculations across Edge, Fog, and Cloud layers. They posit that devices within the same layer share identical capabilities. The total energy $E$ is calculated by integrating power consumption over time across distinct states (idle and active) \cite{saraswat2019energy}:
$$
    E = \int_{T_{idle}} P_{i}(t)dt + \int_{T_{active}} P_{a}(t)dt
$$
Here, $P_{i}(t)$ and $P_{a}(t)$ represent the power consumption per unit time in idle and active states, respectively, while $T_{idle}$ and $T_{active}$ denote the duration the device remains in each state.

A similar state-based logic is adopted by Ahvar et al. \cite{ahvar2019estimating}, though they categorize energy consumption into static (idle) and dynamic (workload-dependent) parts. In their model, the static energy for a node or device is defined as its constant idle power consumption multiplied by the time period $T$, which serves as a discrete equivalent to the integral of a constant power state. 
$$
E^{static} = \sum_{i=1}^{N}(P^{idle}_i T)
$$

\paragraph{b. Physics-Based Component Models}
Adhikari et al. offer a more granular formulation derived from circuit physics, applicable to both IoT devices and Servers. They decompose total power into CPU ($TP^C$) and Memory ($TP^M$) components. The dynamic CPU power is modeled as a function of the square of the supply voltage ($V_{dd}$) \cite{adhikari2019energy}:
$$
    DP^C = \sum_{a=1}^{CR} \beta V_{dd}^2
$$
where $CR$ is the number of cores and $\beta$ is a core-specific constant. Similarly, memory power consumption accounts for both dynamic and static factors:
$$
    TP^M = \underbrace{\frac{1}{2} c V_{dd}^2 f}_{\text{Dynamic}} + A_m
$$
where $c$ is a capacitance constant, $f$ is the frequency, and $A_m$ represents static memory power in the idle state. This formula comes from the funcdamental equation in electrical engineering for CMOS (Complementary metal-oxide-semiconductor) which most modern proessors and memory are built with. Therefore this formula is used in other works to represent power consumption in digital circuit such as in the work of Iftikhar et al. \cite{iftikhar2023hunterplus} where it is used to calculate CPU energy consumption. Furthermore, Adhikari et al. extend this model to quantify carbon footprints ($CE$) using emission factors $\gamma$:
$$
    CE^C(t) = \gamma_{CO_{2}}^C \times TP^C
$$

\subsubsection{Game-Theoretic Edge Server Management}
Cui et al. address the trade-off between minimizing active physical machines and maximizing user coverage through a game-theoretic formulation  \cite{cui2022energy}. Unlike centralized optimization, they model the problem as a Potential Game where users autonomously select servers. To encourage workload consolidation, the decision benefit $B$ for a user joining server is proportional to the user density on that machine:
$$
    B = \frac{N}{e}
$$
where $N$ is the count of users currently served by server $j$, and $e$ is the server's total energy consumption (combining switching and running costs). 

To prevent the system from aggressively dropping users to save power, the global system cost $Z$ balances energy efficiency with a penalty for unserviceability:
$$
    Z = \begin{cases} 
    \frac{e}{N} & \text{Active User} \\
    \alpha \cdot e_0 & \text{Unserved User} 
    \end{cases}
$$
Here, $\alpha$ is a weighting parameter that enables prioritizing service coverage over raw energy savings, ensuring the system converges to a Nash Equilibrium that minimizes wasted energy while maintaining service levels.


\subsection{IoT and End-Device Specifics}
IoT devices, often battery-constrained, require models that account for data readiness and latency. Goudarzi et al. introduce a formulation specifically for IoT application placement. The energy $\omega$ to execute a task is the sum of processing energy and input waiting energy \cite{goudarzi2021distributed}:
$$
    \omega = \omega^{proc} + \omega^{input}
$$
The processing energy is defined by $\omega^{proc} = \psi^{proc} \times P^{CPU}$, where $\psi^{proc} = v/f^s$ (CPU cycles required divided by processing speed). Uniquely, they model the energy cost of waiting for input data ($\omega^{input}$):
$$
    \omega^{input} = \max\left( \frac{e}{b} + l \right) \times P^{tra}
$$
where $e$ is data flow volume, $b$ is bandwidth, $l$ is communication latency, and $P^{tra}$ is the transmission power.

\subsection{Communication and Migration Energy}
Energy consumption in distributed systems is not limited to computation; data transmission and service migration play substantial roles.

\subsubsection{Network Infrastructure}
Jeong et al. model the energy of the network links by focusing on the switching hardware. The energy of a link $E^{link}$ combines static switch energy with per-port consumption \cite{jeong2023towards}:
$$
    E^{link} = E^{static}_{switch} + E^{port}_{switch} \times num_{port}
$$
where $num_{port}$ indicates the number of active ports.

\subsubsection{Transmission and Migration Costs}
For data transmission, Adhikari et al.  utilize a formulation dependent on the bandwidth consumed \cite{adhikari2019energy}:
$$
    TTE = BW \times TT^u + BW \times TT^d
$$
where $TT^u$ and $TT^d$ represent the total time required for uplink and downlink transmission, respectively.

Finally, regarding service reliability and mobility, Jeong et al. quantify the energy cost of migrating a Virtual Machine (VM) as:
$$
    E^{migration} = \alpha \times \frac{VM_{size}}{BW_{link}^{avail}} + \beta
$$
This linear regression model links the VM size and available link bandwidth ($BW_{link}^{avail}$) to energy costs via experimentally determined parameters $\alpha$ and $\beta$.

\subsubsection{Application-Aware Flow Models}
While previous models focus on total transmission duration, Baneshi et al. argue that in the computing continuum (Edge-Fog-Cloud), energy must be attributed to specific applications sharing the infrastructure \cite{baneshi2024analyzing}. They propose a flow-based model specifically for shared infrastructure—such as routers and gateways—that attributes energy costs to specific applications based on their actual resource usage. The model focuses on the Network Interface Card (NIC), which is the primary component responsible for data transfer and energy consumption during networking. Instead of just measuring time, the model calculates the active energy an application consumes by determining its "fair share" of the NIC's workload

$$
    E_{active}^{sh} = \sum_{k \in Intervals} \left( BW \times T_{k} \times \frac{P_{max} - P_{idle}}{BW_{agg}} \right)
$$

where $BW_i$ is the bandwidth consumed by the application, $BW_{agg}$ is the total aggregated bandwidth of the interface, $T_k$ is the duration of the active interval, and $P_{max}$ and $P_{idle}$ denote the power consumption states of the device. This formulation allows for fine-grained energy accounting in multi-tenant scenarios where simple time-based metrics fail to distinguish between concurrent workloads. 


% --- BEGIN ENERGY METRICS TABLE ---
\begin{table}[H]
    \centering
    \small % Use small font to ensure it fits comfortably
    \caption{Summary of Energy Metrics and Measurement Methodologies}
    \label{tab:energy_metrics}

    % Column Definition:
    % Added one extra 'X' column at the end for 'Simu. Param.'
    \begin{tabularx}{\textwidth}{ 
        l                           % Source column
        >{\centering\arraybackslash}X % IoT
        >{\centering\arraybackslash}X % FCs & ESs
        >{\centering\arraybackslash}X % Cloud
        >{\centering\arraybackslash}X % Switch
        >{\centering\arraybackslash}X % Dynamic
        >{\centering\arraybackslash}X % Static
        >{\centering\arraybackslash}X % Measured
        >{\centering\arraybackslash}X % Physical Est.
        >{\centering\arraybackslash}X % Simu. Param.
        }
        
        \toprule
        
        % --- Header Row 1 (Grouped Categories) ---
        \multirow{2}{*}{Source} & 
        \multicolumn{4}{c}{Device Scope} & 
        \multicolumn{2}{c}{Energy Type} & 
        \multicolumn{3}{c}{Methodology} \\ % Extended to 3 columns
        
        % Partial horizontal lines for grouping
        \cmidrule(lr){2-5} \cmidrule(lr){6-7} \cmidrule(lr){8-10}
        
        % --- Header Row 2 (Specific Columns) ---
        & \ac{IoT} & \acp{FC} \& \acp{ES} & \acp{CS} & Switch \& Trans. & Dyn. & Stat. & Meas. & Phys. & Simu. \\
        
        \midrule
        
        % --- DATA ROWS ---
        \cite{laso2025energy} & 
        \xmark & \cmark & \cmark & \xmark & 
        \cmark & \cmark & 
        \cmark & \xmark & \xmark \\
        \midrule

        \cite{baneshi2024analyzing} & 
        \cmark & \cmark & \cmark & \cmark & 
        \cmark & \xmark & 
        \cmark & \xmark & \xmark \\
        \midrule
        
        \cite{paipuri2024ceems} & 
        \xmark & \xmark & \cmark & \cmark & 
        \cmark & \cmark & 
        \cmark & \xmark & \xmark \\
        \midrule
        
        \cite{iftikhar2023hunterplus} & 
        \xmark & \cmark & \cmark & \cmark & 
        \cmark & \cmark & 
        \cmark & \cmark & \xmark \\
        \midrule
        
        \cite{jeong2023towards} & 
        \xmark & \cmark & \xmark & \cmark & 
        \cmark & \cmark & 
        \cmark & \xmark & \xmark \\
        \midrule
        
        \cite{cui2022energy} & 
        \xmark & \cmark & \xmark & \cmark & 
        \cmark & \xmark & 
        \xmark & \xmark & \cmark \\
        \midrule
        
        \cite{naha2022multiple} & 
        \xmark & \cmark & \xmark & \xmark & 
        \cmark & \xmark & 
        \cmark & \xmark & \xmark \\
        \midrule
        
        \cite{goudarzi2021distributed} & 
        \cmark & \xmark & \xmark & \cmark & 
        \cmark & \cmark & 
        \cmark & \xmark & \xmark \\
        \midrule

        \cite{ahvar2019estimating} & 
        \cmark & \cmark & \cmark & \cmark & 
        \cmark & \cmark & 
        \cmark & \xmark & \xmark \\
        \midrule

        \cite{adhikari2019energy} & 
        \cmark & \cmark & \cmark & \cmark & 
        \cmark & \cmark & 
        \xmark & \cmark & \cmark \\
        \midrule
        
        \cite{saraswat2019energy} & 
        \cmark & \cmark & \cmark & \xmark & 
        \cmark & \cmark & 
        \xmark & \xmark & \cmark \\
        \midrule
        
        \bottomrule
    \end{tabularx}
\end{table}
% --- END ENERGY METRICS TABLE ---


\bibliography{references}  

\end{document}
